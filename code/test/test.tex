\documentclass{article}
\usepackage{graphicx}
\usepackage{amsmath,amsfonts,amssymb,graphicx}
\usepackage[a4paper, margin=0.8in]{geometry}
\usepackage{titlesec}


\title{Eigenvalue and Eigenvector Calculations Using a Neural Network}
\author{Raghvendra Mishra \textsubscript{(ME21B1075)} and Ayush Agarwal \textsubscript{(ME21B1076)}}
\date{\today}

\newcommand\tab[1][0.5cm]{\hspace*{#1}}
\begin{document}
\maketitle

\section{Introduction}
Eigenvalue and eigenvector calculations are essential in many areas of science and engineering, from physics and chemistry to computer science and finance. These calculations can be used to solve a wide range of problems, such as determining the stability of a system, analyzing data, and understanding the structure of a network. While there are many methods for calculating eigenvalues and eigenvectors, most of them are iterative and can be computationally expensive, especially for large matrices.
\\ \\
In this paper, we are considering two of these methods that are \large \textbf{Power Method} \normalsize and \large \textbf{Jacobi algorithm} \normalsize to understand how well do they work while scaling and how accurate they are. Along with that, the objective of the paper is to analyze a new way of calculating eigenvalues and eigenvectors, thus testing it's advantages and disadvantages against iterative methods.
\\ \\
Recently, there has been growing interest in using \large \textbf{Neural Networks} \normalsize to calculate eigenvalues and eigenvectors. Neural networks are powerful machine learning tools that can learn complex functions from data and generalize to new data. By training a neural network on a set of matrices and their corresponding eigenvalues and eigenvectors, it is possible to create a model that can predict the eigenvalues and eigenvectors of new matrices with high accuracy and efficiency. 

\section{Literature Review}
\subsection{Eigenvalues and Eigenvectors}

There's usually much blur about what are eigenvalues and eigenvectors and as it is the centerpiece of our topic of discussion, we have to start with a clear understanding of what those terms mean. For this, we need to have a solid understanding of matrices being used as \large \textbf{Linear Transformations} \normalsize.

\subsubsection{Matrices as Linear Transformations}


\subsection{Methods of Eigenvector and Eigenvalue calculation}

There are quite a few methods of calculation of the two such as Power Method, QR Algorithm, Jacobi Algorithm and Singular Value Decomposition (SVD) but for this paper we would be looking at Power Method and Jacobi Algorithm to compare with the proposed way of calculation of the same.

\subsubsection{Power Method}

Let $A$ be a $n \times n$ matrix with $n$ distinct eigenvalues and we order them as,

\[
    |\lambda_{1}| > |\lambda_{2}| > \cdots > |\lambda_{n}| 
\]

with their corresponding eigenvectors,

\[
    e_{1}, e_{2}, \dots, e_{n}
\]  

\subsubsection{Jacobi Algorithm}

Let's say we have a $3 \times 3$ square, symmetric matrix

\[
    A = 
    \begin{bmatrix}
        1 & -2 & 4 \\
        -2 & 5 & -2 \\
        4 & -2 & 1
    \end{bmatrix}  
\]

We note the largest non-diagonal entry in the matrix $A$ as $a_{ij}$, which here makes it $a_{13} = 4$. With this, we are trying to create an orthogonal matrix which Jacobi chose to be as,

\[
    \begin{bmatrix}
        \cos(x) & \cdots & -\sin(x) \\
        \vdots & \ddots & \vdots \\
        \sin(x) & \cdots & \cos(x)    
    \end{bmatrix}
\]

Here, all entries other than the diagonal entries are to $0$ and the diagonal entries other than at both ends of the diagonal are to be $1$.

\section{Methodology}
In this section, describe the methodology you used to carry out your research. Explain the neural network architecture you used and how you trained it to calculate eigenvalues and eigenvectors. Also, explain how you performed the power method calculations and any other methods you used for comparison.

\section{Results}
In this section, present the results of your research. Discuss the accuracy of the neural network in calculating eigenvalues and eigenvectors and compare the results to other methods of calculation.

\section{Discussion}
In this section, discuss the implications of your results and their significance in the context of the problem you are trying to solve. Also, discuss any limitations of your study and suggest future research directions.

\section{Conclusion}
In this section, summarize the main findings of your study and reiterate their importance. Provide some final thoughts on the topic and suggest areas for further research.

\section{References}
In this section, list all the sources you cited in your report. Use a consistent citation style, such as APA or MLA.

\end{document}